{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahid-isu/clip-field-demo/blob/main/clipfield_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTsNNb7_rQel",
        "outputId": "488b9a99-aa68-447c-95a9-ee4a77b29777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --recursive https://github.com/notmahi/clip-fields"
      ],
      "metadata": {
        "id": "JIyU5kv31BTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIVwPBdo1Mui",
        "outputId": "a4a674d9-f01b-412a-9e71-06c1730458f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/clp/clip-fields\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y wget\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local\n",
        "!conda init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffi4xLjF3B6G",
        "outputId": "74bfc63a-baa6-4884-8401-f72645bdf1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "Hit:9 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,377 kB]\n",
            "Fetched 2,395 kB in 3s (716 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "wget is already the newest version (1.20.3-1ubuntu2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 28 not upgraded.\n",
            "--2023-01-24 02:12:06--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8203, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72402405 (69M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh.2’\n",
            "\n",
            "Miniconda3-latest-L 100%[===================>]  69.05M  70.3MB/s    in 1.0s    \n",
            "\n",
            "2023-01-24 02:12:07 (70.3 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh.2’ saved [72402405/72402405]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Extracting : libcublas-11.9.2.110-h5e84587_0.tar.bz2:  97% 132/136 [05:09<00:15,  3.77s/it]Failed extraction with libarchive... falling back to python implementation\n",
            "concurrent.futures.process._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"conda_package_handling/tarball.py\", line 155, in extract\n",
            "  File \"conda_package_handling/tarball.py\", line 103, in _tar_xf\n",
            "  File \"conda_package_handling/archive_utils.py\", line 15, in extract_file\n",
            "conda_package_handling.exceptions.InvalidArchiveError: Error with archive /usr/local/pkgs/nsight-compute-2022.4.0.15-0.tar.bz2.  You probably need to delete and re-download or re-create this file.  Message from libarchive was:\n",
            "\n",
            "truncated bzip2 input\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"concurrent/futures/process.py\", line 246, in _process_worker\n",
            "  File \"concurrent/futures/process.py\", line 205, in _process_chunk\n",
            "  File \"concurrent/futures/process.py\", line 205, in <listcomp>\n",
            "  File \"conda_package_handling/api.py\", line 57, in extract\n",
            "  File \"conda_package_handling/tarball.py\", line 160, in extract\n",
            "  File \"conda_package_handling/tarball.py\", line 112, in _tar_xf_no_libarchive\n",
            "  File \"tarfile.py\", line 1808, in getmembers\n",
            "  File \"tarfile.py\", line 2406, in _load\n",
            "  File \"tarfile.py\", line 2328, in next\n",
            "  File \"bz2.py\", line 275, in seek\n",
            "  File \"_compression.py\", line 143, in seek\n",
            "  File \"_compression.py\", line 99, in read\n",
            "EOFError: Compressed file ended before the end-of-stream marker was reached\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"entry_point.py\", line 69, in <module>\n",
            "  File \"concurrent/futures/process.py\", line 562, in _chain_from_iterable_of_lists\n",
            "  File \"concurrent/futures/_base.py\", line 609, in result_iterator\n",
            "  File \"concurrent/futures/_base.py\", line 446, in result\n",
            "  File \"concurrent/futures/_base.py\", line 391, in __get_result\n",
            "EOFError: Compressed file ended before the end-of-stream marker was reached\n",
            "[43283] Failed to execute script 'entry_point' due to unhandled exception!\n",
            "no change     /usr/local/condabin/conda\n",
            "no change     /usr/local/bin/conda\n",
            "no change     /usr/local/bin/conda-env\n",
            "no change     /usr/local/bin/activate\n",
            "no change     /usr/local/bin/deactivate\n",
            "no change     /usr/local/etc/profile.d/conda.sh\n",
            "no change     /usr/local/etc/fish/conf.d/conda.fish\n",
            "no change     /usr/local/shell/condabin/Conda.psm1\n",
            "no change     /usr/local/shell/condabin/conda-hook.ps1\n",
            "no change     /usr/local/lib/python3.10/site-packages/xontrib/conda.xsh\n",
            "no change     /usr/local/etc/profile.d/conda.csh\n",
            "no change     /root/.bashrc\n",
            "No action taken.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMBcFvVd3VIG",
        "outputId": "9534ec34-cb91-4f7f-a92b-1e2b2b6254ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# conda environments:\n",
            "#\n",
            "base                     /usr/local\n",
            "cf                       /usr/local/envs/cf\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate cf"
      ],
      "metadata": {
        "id": "U5D8qz6l3oJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install -y pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch-lts -c nvidia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLIa93vt3q8L",
        "outputId": "93583c42-d2cf-46fd-a42b-ce3a337c3601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \n",
            "Found conflicts! Looking for incompatible packages.\n",
            "This can take several minutes.  Press CTRL-C to abort.\n",
            "\b\bfailed\n",
            "\n",
            "UnsatisfiableError: The following specifications were found\n",
            "to be incompatible with the existing python installation in your environment:\n",
            "\n",
            "Specifications:\n",
            "\n",
            "  - torchaudio -> python[version='>=3.6,<3.7.0a0|>=3.9,<3.10.0a0|>=3.7,<3.8.0a0|>=3.8,<3.9.0a0']\n",
            "\n",
            "Your python: python=3.10\n",
            "\n",
            "If python is on the left-most side of the chain, that's the version you've asked for.\n",
            "When python appears to the right, that indicates that the thing on the left is somehow\n",
            "not available for the python version you are constrained to. Note that conda will not\n",
            "change your python version to a different minor version unless you explicitly specify\n",
            "that.\n",
            "\n",
            "The following specifications were found to be incompatible with each other:\n",
            "\n",
            "Output in format: Requested package -> Available versions\n",
            "\n",
            "Package typing conflicts for:\n",
            "pytorch -> typing_extensions -> typing[version='>=3.7.4']\n",
            "pytorch -> typing\n",
            "\n",
            "Package pyyaml conflicts for:\n",
            "torchvision -> pytorch -> pyyaml\n",
            "pytorch -> pyyaml\n",
            "\n",
            "Package libstdcxx-ng conflicts for:\n",
            "torchaudio -> numpy[version='>=1.11'] -> libstdcxx-ng[version='>=11.2.0|>=7.5.0|>=7.3.0|>=7.2.0']\n",
            "cudatoolkit=11.1 -> libstdcxx-ng[version='>=7.3.0|>=9.3.0']\n",
            "torchvision -> libstdcxx-ng[version='>=11.2.0|>=7.3.0|>=5.4.0']\n",
            "torchvision -> cudatoolkit[version='>=11.1,<11.2'] -> libstdcxx-ng[version='>=7.2.0|>=7.5.0|>=9.3.0|>=8.4.0']\n",
            "pytorch -> libstdcxx-ng[version='>=5.4.0|>=7.3.0|>=7.5.0|>=9.3.0']\n",
            "pytorch -> mkl[version='>=2018'] -> libstdcxx-ng[version='>=11.2.0|>=7.2.0']\n",
            "python=3.10 -> libffi[version='>=3.4,<3.5'] -> libstdcxx-ng[version='>=11.2.0|>=7.5.0|>=7.3.0']\n",
            "\n",
            "Package pytorch conflicts for:\n",
            "torchaudio -> pytorch[version='1.8.1|1.8.2']\n",
            "torchvision -> pytorch[version='1.1.*|1.10.2|1.8.1|1.8.2|1.7.1.*|1.3.1.*|1.2.0.*|>=0.4|>=0.3']\n",
            "\n",
            "Package _libgcc_mutex conflicts for:\n",
            "pytorch -> _openmp_mutex -> _libgcc_mutex[version='*|0.1',build=main]\n",
            "torchvision -> libgcc-ng[version='>=11.2.0'] -> _libgcc_mutex[version='*|0.1',build=main]\n",
            "python=3.10 -> libgcc-ng[version='>=11.2.0'] -> _libgcc_mutex[version='*|0.1',build=main]\n",
            "cudatoolkit=11.1 -> libgcc-ng[version='>=7.3.0'] -> _libgcc_mutex[version='*|0.1',build=main]\n",
            "\n",
            "Package libuuid conflicts for:\n",
            "python=3.10 -> libuuid[version='>=1.0.3,<2.0a0|>=1.41.5,<2.0a0']\n",
            "pytorch -> python[version='>=3.10,<3.11.0a0'] -> libuuid[version='>=1.0.3,<2.0a0|>=1.41.5,<2.0a0']\n",
            "torchvision -> python[version='>=3.10,<3.11.0a0'] -> libuuid[version='>=1.0.3,<2.0a0|>=1.41.5,<2.0a0']\n",
            "\n",
            "Package setuptools conflicts for:\n",
            "torchvision -> setuptools\n",
            "python=3.10 -> pip -> setuptools\n",
            "\n",
            "Package python_abi conflicts for:\n",
            "torchvision -> python_abi=3.9[build=*_cp39]\n",
            "torchaudio -> python_abi=3.9[build=*_cp39]\n",
            "\n",
            "Package cudatoolkit conflicts for:\n",
            "torchaudio -> pytorch==1.8.2 -> cudatoolkit[version='>=10.1,<10.2|>=11.1,<11.2|>=10.2,<10.3']\n",
            "torchvision -> pytorch -> cudatoolkit[version='10.0.*|>=10.1.243,<10.2.0a0|>=11.3.1,<11.4.0a0|9.2.*|>=8.0,<8.1.0a0|9.0.*|8.0.*|7.5.*']\n",
            "torchvision -> cudatoolkit[version='>=10.0.130,<10.1.0a0|>=10.1,<10.2|>=11.1,<11.2|>=10.2,<10.3|>=9.2,<9.3.0a0|>=9.0,<9.1.0a0']The following specifications were found to be incompatible with your system:\n",
            "\n",
            "  - feature:/linux-64::__glibc==2.31=0\n",
            "  - feature:|@/linux-64::__glibc==2.31=0\n",
            "  - cudatoolkit=11.1 -> __glibc[version='>=2.17,<3.0.a0']\n",
            "  - cudatoolkit=11.1 -> libgcc-ng[version='>=7.3.0'] -> __glibc[version='>=2.17']\n",
            "  - python=3.10 -> libgcc-ng[version='>=11.2.0'] -> __glibc[version='>=2.17']\n",
            "  - torchvision -> __glibc[version='>=2.17,<3.0.a0']\n",
            "  - torchvision -> libgcc-ng[version='>=11.2.0'] -> __glibc[version='>=2.17']\n",
            "\n",
            "Your installed version is: 2.31\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZNwzBOF3w97",
        "outputId": "8eeb5aa7-c608-4800-d78a-5a1a1e759250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/CLIP.git (from -r requirements.txt (line 3))\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-r4_280mu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-r4_280mu\n",
            "  Resolved https://github.com/openai/CLIP.git to commit 3702849800aa56e2223035bccd1c6ef91c704ca8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git (from -r requirements.txt (line 10))\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-6i4m3oyu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-6i4m3oyu\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 58e472e076a5d861fdcf773d9254a3664e045bf8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.5.4\n",
            "  Using cached timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "Collecting hydra-core==1.2.0\n",
            "  Using cached hydra_core-1.2.0-py3-none-any.whl (151 kB)\n",
            "Collecting ftfy==6.1.1\n",
            "  Using cached ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "Collecting tqdm==4.64.0\n",
            "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "Collecting regex==2019.11.1\n",
            "  Using cached regex-2019.11.1.tar.gz (669 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting point-transformer-pytorch==0.1.5\n",
            "  Using cached point_transformer_pytorch-0.1.5-py3-none-any.whl (5.7 kB)\n",
            "Collecting sentence_transformers==2.2.2\n",
            "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy-quaternion==2022.4.2\n",
            "  Using cached numpy_quaternion-2022.4.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
            "Collecting pandas==1.4.3\n",
            "  Using cached pandas-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "Collecting pyntcloud==0.3.1\n",
            "  Using cached pyntcloud-0.3.1-py2.py3-none-any.whl (346 kB)\n",
            "Collecting hydra-submitit-launcher==1.2.0\n",
            "  Using cached hydra_submitit_launcher-1.2.0-py3-none-any.whl (5.2 kB)\n",
            "Collecting torch-encoding==1.2.2b20200804\n",
            "  Using cached torch_encoding-1.2.2b20200804-py2.py3-none-any.whl (126 kB)\n",
            "Collecting torchmetrics==0.6.0\n",
            "  Using cached torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n",
            "Collecting opencv-python==4.5.5.64\n",
            "  Using cached opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
            "Collecting imageio==2.19.3\n",
            "  Using cached imageio-2.19.3-py3-none-any.whl (3.4 MB)\n",
            "Collecting altair==4.2.0\n",
            "  Using cached altair-4.2.0-py3-none-any.whl (812 kB)\n",
            "Collecting streamlit==1.12.2\n",
            "  Using cached streamlit-1.12.2-py2.py3-none-any.whl (9.1 MB)\n",
            "Collecting protobuf==3.20.1\n",
            "  Using cached protobuf-3.20.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "Collecting matplotlib==3.5.2\n",
            "  Using cached matplotlib-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n",
            "Collecting test-tube==0.7.5\n",
            "  Using cached test_tube-0.7.5.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb==0.13.3\n",
            "  Using cached wandb-0.13.3-py2.py3-none-any.whl (1.8 MB)\n",
            "Collecting omegaconf==2.2.2\n",
            "  Using cached omegaconf-2.2.2-py3-none-any.whl (79 kB)\n",
            "Collecting numpy==1.21.4\n",
            "  Using cached numpy-1.21.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "Collecting einops==0.4.1\n",
            "  Using cached einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Collecting pytorch-lightning==1.3.5\n",
            "  Using cached pytorch_lightning-1.3.5-py3-none-any.whl (808 kB)\n",
            "Requirement already satisfied: pyquaternion==0.9.9 in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 29)) (0.9.9)\n",
            "Requirement already satisfied: pyliblzfse==0.4.1 in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 30)) (0.4.1)\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 0.55.2 Requires-Python <3.5\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement open3d==0.15.2 (from versions: 0.16.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for open3d==0.15.2\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export CUDA_HOME=/usr/local/cuda\n",
        "%cd gridencoder"
      ],
      "metadata": {
        "id": "sfBpGcr346xv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fae108d0-8d41-4b8a-c1fb-e24ca3d9dea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/clp/clip-fields/gridencoder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install pytorch torchvision torchaudio pytorch-cuda=11.6 -c pytorch -c nvidia"
      ],
      "metadata": {
        "id": "ZVpE0_wh7plj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erBT8ae1720e",
        "outputId": "db36b79d-bb4b-4f78-8e6b-fa2d5587ca56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running install\n",
            "/usr/local/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
            "  warnings.warn(\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing gridencoder.egg-info/PKG-INFO\n",
            "writing dependency_links to gridencoder.egg-info/dependency_links.txt\n",
            "writing top-level names to gridencoder.egg-info/top_level.txt\n",
            "/usr/local/lib/python3.10/site-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest file 'gridencoder.egg-info/SOURCES.txt'\n",
            "writing manifest file 'gridencoder.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/site-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.2) has a minor version mismatch with the version that was used to compile PyTorch (11.6). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-cpython-310/_gridencoder.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for _gridencoder.cpython-310-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/_gridencoder.py to _gridencoder.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gridencoder.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gridencoder.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gridencoder.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gridencoder.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__._gridencoder.cpython-310: module references __file__\n",
            "creating 'dist/gridencoder-0.0.0-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing gridencoder-0.0.0-py3.10-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.10/site-packages/gridencoder-0.0.0-py3.10-linux-x86_64.egg\n",
            "Extracting gridencoder-0.0.0-py3.10-linux-x86_64.egg to /usr/local/lib/python3.10/site-packages\n",
            "Adding gridencoder 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/site-packages/gridencoder-0.0.0-py3.10-linux-x86_64.egg\n",
            "Processing dependencies for gridencoder==0.0.0\n",
            "Finished processing dependencies for gridencoder==0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/clp/clip-fields"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDdJ2IxaC3Pc",
        "outputId": "d2c6a0dc-bf0f-4cde-f660-cc5c59457aa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/clp/clip-fields\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXjByrLzDUsz",
        "outputId": "b23c2539-f1aa-4cf3-cb96-ebb8501fa4ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ninja-linux.zip\n",
            "replace /usr/local/bin/ninja? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: /usr/local/bin/ninja    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7cSVwcI-qnY",
        "outputId": "cd08f8b6-2a20-4b19-f584-b2a6c57382ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/local/bin/ninja to provide /usr/bin/ninja (ninja) in auto mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!update-alternatives: using /usr/local/bin/ninja to provide /usr/bin/ninja (ninja) in auto mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH5g5sC6-t7N",
        "outputId": "ed17fbc3-f2c1-439e-ba99-1570df032fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 0: `update-alternatives: using /usr/local/bin/ninja to provide /usr/bin/ninja (ninja) in auto mode'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which ninja"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtclkCVm-yZF",
        "outputId": "8c90a92b-1146-482d-d1bf-4873899448a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/ninja\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=$PATH:/usr/local"
      ],
      "metadata": {
        "id": "RsefEE_kMElf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python train.py dataset_path=nyu.r3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghYJIJzjVlL9",
        "outputId": "db1140fe-48e2-4435-b138-d1e32fde4dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1900, in _run_ninja_build\n",
            "    subprocess.run(\n",
            "  File \"/usr/local/lib/python3.10/subprocess.py\", line 526, in run\n",
            "    raise CalledProcessError(retcode, process.args,\n",
            "subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/clp/clip-fields/train.py\", line 17, in <module>\n",
            "    from dataloaders import (\n",
            "  File \"/content/drive/MyDrive/clp/clip-fields/dataloaders/__init__.py\", line 3, in <module>\n",
            "    from dataloaders.real_dataset import DeticDenseLabelledDataset\n",
            "  File \"/content/drive/MyDrive/clp/clip-fields/dataloaders/real_dataset.py\", line 39, in <module>\n",
            "    from encoding.models.sseg import BaseNet\n",
            "  File \"/usr/local/lib/python3.10/site-packages/encoding/__init__.py\", line 13, in <module>\n",
            "    from . import nn, functions, parallel, utils, models, datasets, transforms\n",
            "  File \"/usr/local/lib/python3.10/site-packages/encoding/nn/__init__.py\", line 12, in <module>\n",
            "    from .encoding import *\n",
            "  File \"/usr/local/lib/python3.10/site-packages/encoding/nn/encoding.py\", line 18, in <module>\n",
            "    from ..functions import scaled_l2, aggregate, pairwise_cosine\n",
            "  File \"/usr/local/lib/python3.10/site-packages/encoding/functions/__init__.py\", line 2, in <module>\n",
            "    from .encoding import *\n",
            "  File \"/usr/local/lib/python3.10/site-packages/encoding/functions/encoding.py\", line 14, in <module>\n",
            "    from .. import lib\n",
            "  File \"/usr/local/lib/python3.10/site-packages/encoding/lib/__init__.py\", line 19, in <module>\n",
            "    gpu = load('enclib_gpu', [\n",
            "  File \"/usr/local/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1284, in load\n",
            "    return _jit_compile(\n",
            "  File \"/usr/local/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1508, in _jit_compile\n",
            "    _write_ninja_file_and_build_library(\n",
            "  File \"/usr/local/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1623, in _write_ninja_file_and_build_library\n",
            "    _run_ninja_build(\n",
            "  File \"/usr/local/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1916, in _run_ninja_build\n",
            "    raise RuntimeError(message) from e\n",
            "RuntimeError: Error building extension 'enclib_gpu': [1/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=enclib_gpu -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' --expt-extended-lambda -std=c++14 -c /usr/local/lib/python3.10/site-packages/encoding/lib/gpu/lib_ssd.cu -o lib_ssd.cuda.o \n",
            "FAILED: lib_ssd.cuda.o \n",
            "/usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=enclib_gpu -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' --expt-extended-lambda -std=c++14 -c /usr/local/lib/python3.10/site-packages/encoding/lib/gpu/lib_ssd.cu -o lib_ssd.cuda.o \n",
            "/usr/local/lib/python3.10/site-packages/encoding/lib/gpu/lib_ssd.cu:22:10: fatal error: THC/THCNumerics.cuh: No such file or directory\n",
            "   22 | #include <THC/THCNumerics.cuh>\n",
            "      |          ^~~~~~~~~~~~~~~~~~~~~\n",
            "compilation terminated.\n",
            "[2/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=enclib_gpu -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' --expt-extended-lambda -std=c++14 -c /usr/local/lib/python3.10/site-packages/encoding/lib/gpu/rectify_cuda.cu -o rectify_cuda.cuda.o \n",
            "FAILED: rectify_cuda.cuda.o \n",
            "/usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=enclib_gpu -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' --expt-extended-lambda -std=c++14 -c /usr/local/lib/python3.10/site-packages/encoding/lib/gpu/rectify_cuda.cu -o rectify_cuda.cuda.o \n",
            "/usr/local/lib/python3.10/site-packages/encoding/lib/gpu/rectify_cuda.cu(114): error: identifier \"ScalarConvert\" is undefined\n",
            "\n",
            "/usr/local/lib/python3.10/site-packages/encoding/lib/gpu/rectify_cuda.cu(114): error: type name is not allowed\n",
            "\n",
            "/usr/local/lib/python3.10/site-packages/encoding/lib/gpu/rectify_cuda.cu(114): error: type name is not allowed\n",
            "\n",
            "/usr/local/lib/python3.10/site-packages/encoding/lib/gpu/rectify_cuda.cu(114): error: the global scope has no \"to\"\n",
            "\n",
            "4 errors detected in the compilation of \"/usr/local/lib/python3.10/site-packages/encoding/lib/gpu/rectify_cuda.cu\".\n",
            "ninja: build stopped: subcommand failed.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls!conda list"
      ],
      "metadata": {
        "id": "N4vckN2oryFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9tF7Z-vdvGjg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}